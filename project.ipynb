{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab05b99",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54e60c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import advertools as adv\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250c9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('IMDB-Dataset.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6770edd",
   "metadata": {},
   "source": [
    "Explore dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec894d05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218e376",
   "metadata": {},
   "source": [
    "Check for emojis using an external library \"advertools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca316f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emojis: 21\n",
      "['â˜º', 'â¤', 'ðŸ’•', 'ðŸ˜Š', 'ðŸ˜‡', 'ðŸ˜‰', 'ðŸ˜Œ', 'ðŸ˜', 'ðŸ¥°', 'ðŸ˜—', 'ðŸ˜™', 'ðŸ˜š', 'ðŸ˜š', 'ðŸ˜‹', 'ðŸ˜›', 'ðŸ˜', 'ðŸ˜œ', 'ðŸ¤ª', 'ðŸ¤¨', 'ðŸ§', 'ðŸ˜Ž']\n"
     ]
    }
   ],
   "source": [
    "#Testing emojis\n",
    "testEmojiDict = adv.extract_emoji(\"Hi â˜ºï¸ My name is Mo B. I love data scienceâ¤ï¸ðŸ’•ðŸ˜ŠðŸ˜‡ðŸ˜‰ðŸ˜ŒðŸ˜ðŸ¥°ðŸ˜—ðŸ˜™ðŸ˜šðŸ˜šðŸ˜‹ðŸ˜›ðŸ˜ðŸ˜œðŸ¤ªðŸ¤¨ðŸ§ðŸ˜Ž\")\n",
    "\n",
    "count = 0\n",
    "for emoji_count in testEmojiDict['emoji_counts']:\n",
    "    if (emoji_count >= 1):\n",
    "        count +=1\n",
    "print(\"Total emojis:\", count)\n",
    "print(testEmojiDict['emoji_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aad0e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = adv.extract_emoji(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7bebce45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emojis: 0\n",
      "['Â®', 'Â®', 'Â®', 'Â©', 'Â®']\n",
      "['registered', 'registered', 'registered', 'copyright', 'registered']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for emoji_count in emoji_dict['emoji_counts']:\n",
    "    if (emoji >= 1):\n",
    "        count +=1\n",
    "print(\"Total emojis:\", count)\n",
    "\n",
    "print(emoji_dict['emoji_flat'])\n",
    "print(emoji_dict['emoji_flat_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a1eb5",
   "metadata": {},
   "source": [
    "Seems like they are no emojis in the dataframe. Bear in mind data has not been altered in any way as of yet. Only Registered and copyright symbols are found which would not have any effect on the sentiment analyser whatsoever. Therefore they will be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08ceb1",
   "metadata": {},
   "source": [
    "Considerable number of reviews contained HTML tags, as well as brackets. Therefore they are removed.\n",
    "Special characters are removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a00eddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "#Removing the noisy text\n",
    "def clean_text(text):\n",
    "    text = remove_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_special_characters(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa58ab3",
   "metadata": {},
   "source": [
    "Tokenise and normalise words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01b55949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/moham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "def stem_words(tokenizedList):\n",
    "    stemmedList = []\n",
    "    for word in tokenizedList:\n",
    "        stemmedList.append(stemmer.stem(word))\n",
    "    return stemmedList\n",
    "\n",
    "def smarter_tokenize_and_preprocess(text):\n",
    "    tokenizedWords = nltk.word_tokenize(text)\n",
    "    return stem_words(tokenizedWords)\n",
    "df['review'] = df['review'].apply(smarter_tokenize_and_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63a6c0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [one, of, the, other, review, has, mention, th...\n",
       "1        [a, wonder, littl, product, the, film, techniq...\n",
       "2        [i, thought, this, was, a, wonder, way, to, sp...\n",
       "3        [basic, there, a, famili, where, a, littl, boy...\n",
       "4        [petter, mattei, love, in, the, time, of, mone...\n",
       "                               ...                        \n",
       "49995    [i, thought, this, movi, did, a, down, right, ...\n",
       "49996    [bad, plot, bad, dialogu, bad, act, idiot, dir...\n",
       "49997    [i, am, a, cathol, taught, in, parochi, elemen...\n",
       "49998    [im, go, to, have, to, disagre, with, the, pre...\n",
       "49999    [no, one, expect, the, star, trek, movi, to, b...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3dac1b",
   "metadata": {},
   "source": [
    "Possibly use tf-idf, can be used with logistic regression. More on that later when we pick a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82853d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
