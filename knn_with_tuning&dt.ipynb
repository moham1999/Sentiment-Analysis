{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67aeddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import numpy as np\n",
    "#import advertools as adv\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e542a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\pavuc\\Documents\\CompSci\\ML\\.ipynb_checkpoints\\IMDB-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0d8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "#took this from you Mo :D\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removes URL\n",
    "def remove_url(data):\n",
    "    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n",
    "    data=url_clean.sub(r'',data)\n",
    "    return data\n",
    "\n",
    "#Removes the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removes special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "#Removing the noisy text\n",
    "def clean_text(text):\n",
    "    text = remove_html(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_special_characters(text)\n",
    "    return text\n",
    "\n",
    "#Apply function on review column\n",
    "df['review'] = df['review'].apply(clean_text)\n",
    "#map ratings to 1 and 0 for plotting ROC\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88109f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn import metrics\n",
    "\n",
    "X = df.review\n",
    "y = df.sentiment\n",
    "\n",
    "vect = CountVectorizer(analyzer = 'word', stop_words = 'english')\n",
    "\n",
    "#splitting the dataset, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "#vectorizing \n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.fit_transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "#training the knn model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_dtm, y_train)\n",
    "y_pred_knn = knn.predict(X_test_dtm)\n",
    "\n",
    "#training the decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train_dtm, y_train)\n",
    "y_pred_dt = dt.predict(X_test_dtm)\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "#for plotting ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "probs_knn = knn.predict_proba(X_test_dtm)\n",
    "fpr1, tpr1, threshold1 = metrics.roc_curve(y_test, probs_knn[:,1])\n",
    "roc_auc_knn = metrics.auc(fpr1, tpr1)\n",
    "\n",
    "probs_dt = knn.predict_proba(X_test_dtm)\n",
    "fpr2, tpr2, threshold2 = metrics.roc_curve(y_test, probs_dt[:,1])\n",
    "roc_auc_dt = metrics.auc(fpr2, tpr2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('ROC')\n",
    "#plt.plot(fpr1, tpr1, 'b', label = 'AUC = %0.2f' % roc_auc_knn)\n",
    "#plt.plot(fpr2, tpr2, 'b', label = 'AUC = %0.2f' % roc_auc_dt)\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='KNN')\n",
    "plt.plot(fpr2, tpr2, linestyle='--',color='green', label='Decision Tree')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\nK Nearest Neighbors (NN = 3)')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred_knn)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred_knn), sep = '\\n')\n",
    "\n",
    "print('\\nDecision Tree')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred_dt)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred_dt), sep = '\\n')\n",
    "\n",
    "#hyperparameter tuning for knn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbours = list(range(1,30))\n",
    "p =[1,2]\n",
    "\n",
    "hyperparameters = dict(leaf_size = leaf_size, n_neighbours = n_neighbours, p=p)\n",
    "knn_2 = KNeighborsClassifie()\n",
    "\n",
    "#grid search\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "best_model = clf.fit(X,y)\n",
    "\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7f7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec217f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
