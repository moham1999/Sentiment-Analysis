{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "# import advertools\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy\n",
    "# 0.24.2\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love paul mccartney greatest time could not ho...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>steven seagal back third film releas year cour...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movi start brisk slow moment middl general mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alway love old movi one top ten favorit charm ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guy ritchi nobl effort beat knock rape kick ar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one big best jack hulbert singl role split two...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pat obrien best role ever notr dame footbal co...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rent film girlfriend away hope see serious mil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>opinion flatley ruin first show ridicul ego di...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wonder one best music ever three busbi berk nu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  love paul mccartney greatest time could not ho...  positive\n",
       "1  steven seagal back third film releas year cour...  negative\n",
       "2  movi start brisk slow moment middl general mov...  positive\n",
       "3  alway love old movi one top ten favorit charm ...  positive\n",
       "4  guy ritchi nobl effort beat knock rape kick ar...  negative\n",
       "5  one big best jack hulbert singl role split two...  positive\n",
       "6  pat obrien best role ever notr dame footbal co...  positive\n",
       "7  rent film girlfriend away hope see serious mil...  negative\n",
       "8  opinion flatley ruin first show ridicul ego di...  positive\n",
       "9  wonder one best music ever three busbi berk nu...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = pandas.read_csv(\"IMDB-Dataset-training.csv\")\n",
    "df_training.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "text_fitter = cv.fit(df_training['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    features = text_fitter.transform(df['review']).toarray()\n",
    "    targets = numpy.array(df['sentiment'].apply(lambda x: int(x=='positive')))\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, training_targets = get_data(df_training)\n",
    "classifier = MultinomialNB()\n",
    "fit_data = list(zip(numpy.array_split(training_features, 1000), numpy.array_split(training_targets, 1000)))\n",
    "# i = 0\n",
    "for f,t in fit_data:\n",
    "    # print(i)\n",
    "    # i+=1\n",
    "    classifier.partial_fit(f, t, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_data(features, targets):\n",
    "    df = pandas.DataFrame({'true_T':[0,0], 'true_F':[0,0]}, index=['predicted_T','predicted_F'])\n",
    "    for f, t in zip(features, targets):\n",
    "        try:\n",
    "            prediction = classifier.predict([f])[0]\n",
    "            df['true_T' if bool(t) else 'true_F']['predicted_T' if bool(prediction) else 'predicted_F']+=1\n",
    "        except:\n",
    "            pass\n",
    "        finally:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.score(features, targets)\n",
    "score_data(training_features, training_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pandas.read_csv(\"IMDB-Dataset-validation.csv\")\n",
    "df_validation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features, validation_targets = get_data(df_validation)\n",
    "# classifier.score(validation_features, validation_targets)\n",
    "score_data(validation_features, validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB:\n",
    "\n",
    "Training | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 11451 | 288 |\n",
    "predicted_F | 8565 | 19696 |\n",
    "\n",
    "\n",
    "Validation | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 1125 | 400 |\n",
    "predicted_F | 1368 | 2107 |\n",
    "\n",
    "# ComplementNB:\n",
    "\n",
    "Training | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 17190 | 1780 |\n",
    "predicted_F | 2826 | 18204 |\n",
    "\n",
    "\n",
    "Validation | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 2057 | 344 |\n",
    "predicted_F | 436 | 2163 |\n",
    "\n",
    "# CategoricalNB:\n",
    "\n",
    "Training | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 17394 | 1388 |\n",
    "predicted_F | 2622 | 18596 |\n",
    "\n",
    "\n",
    "Validation | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 1599 | 235 |\n",
    "predicted_F | 400 | 1721 |\n",
    "\n",
    "# MultinomialNB:\n",
    "\n",
    "Training | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 17190 | 1780 |\n",
    "predicted_F | 2826 | 18204 |\n",
    "\n",
    "\n",
    "Validation | true_T | true_F |\n",
    "---|---|---|\n",
    "predicted_T | 2057 | 345 |\n",
    "predicted_F | 436 | 2162 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.predict([validation_features[0]])\n",
    "# [validation_features[0]]\n",
    "v = set(validation_features[0])\n",
    "tr = map(lambda x: set(x), training_features)\n",
    "tr_2 = set()\n",
    "for se in tr:\n",
    "    tr_2.update(se)\n",
    "tr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pass\n",
    "finally:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42d89d09b6e513e23bf727853989dcbd4248dd80e4876aabc1efc1627826ab68"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
